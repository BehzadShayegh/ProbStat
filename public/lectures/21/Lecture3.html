<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
    <div class="jp-Cell-inputWrapper">
    <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
    </div>
    <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
    </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
    <h3 id="%D8%AA%D8%A7%D8%A8%D8%B9-%D8%AF%D8%B1%D8%B3%D8%AA-%D9%86%D9%85%D8%A7%DB%8C%DB%8C:">&#1578;&#1575;&#1576;&#1593; &#1583;&#1585;&#1587;&#1578; &#1606;&#1605;&#1575;&#1740;&#1740;:</h3>$$ L(\ \theta)\ =\ \prod_{i=1}^{n}{f(xi|}\theta) $$<h3 id="%D8%AA%D8%AE%D9%85%DB%8C%D9%86-%D8%AF%D8%B1%D8%B3%D8%AA%E2%80%8C%D9%86%D9%85%D8%A7%DB%8C%DB%8C-%D8%A8%DB%8C%D8%B4%DB%8C%D9%86%D9%87:">&#1578;&#1582;&#1605;&#1740;&#1606; &#1583;&#1585;&#1587;&#1578;&#8204;&#1606;&#1605;&#1575;&#1740;&#1740; &#1576;&#1740;&#1588;&#1740;&#1606;&#1607;:</h3><p>تخمینگر درست‌نمایی بیشینه که آن را با $ {\emptyset s}\_{ML} $ نماش می‌دهیم، در حقیقت مقداری از پارامتر $ \emptyset $ است که تابع $ L(\emptyset) $ را بیشینه می‌کند.</p>
    $$ {\theta\ }_{ML}=\ arg\ max\ \theta\ L(\theta) $$<h3 id="%D8%AA%D8%AE%D9%85%DB%8C%D9%86-ML:">&#1578;&#1582;&#1605;&#1740;&#1606; ML:</h3><p>جهت یافتن $ \emptyset\_{ML} $ باید از تابع $ L(\emptyset) $ نسبت به $ \emptyset $ مشتق بگیرید:</p>
    $$ \frac{d}{d\theta}\ \prod_{i=1}^{n}{f(xi|}\theta)\ =\ \theta $$<p>اما از آنجا که $ L(ϴ) $ یک تابع ضربی است، مشتق آن پیچیده می‌شود. به همین دلیل غالبا از لگاریتم آن که یک تابع جمعی می‌شود استفاده می‌کنیم که آن را تابع درست‌نمایی لگاریتمی می‌نامیم:</p>
    $$ LL(\theta ) = lnL(\theta ) = ln\prod_{i=1}^{n}f(xi|\theta )=\sum_{n}^{i=0}ln f(xi|\theta ) $$<p>با توجه به صعولی اکید بودن تابع لگاریتم، مقداری که از $ ϴ $ که تابع $ L(ϴ) $ را بیشینه می‌کند، تابع $ L(ϴ) $ را هم بی‌شینه خواهد کرد:</p>
    $$ arg max LL(ϴ) = arg max L(ϴ) = {\emptyset s}_{ML} $$<h3 id="%D8%AA%D8%AE%D9%85%DB%8C%D9%86-ML-%D8%A8%DB%8C%D8%B4-%D8%A7%D8%B2-%DB%8C%DA%A9-%D9%BE%D8%A7%D8%B1%D8%A7%D9%85%D8%AA%D8%B1:">&#1578;&#1582;&#1605;&#1740;&#1606; ML &#1576;&#1740;&#1588; &#1575;&#1586; &#1740;&#1705; &#1662;&#1575;&#1585;&#1575;&#1605;&#1578;&#1585;:</h3><p>فرض کنید می‌خواهیم پارامترهای $ ɥ $ و $ ɑ $ از توزیع نرمال را تخمین بزنیم. به این منظور باید از تابع درست‌نمایی یک بار نسبت به $ ɥ $ و بار دیگر نسبت به $ ɑ $ مشتق بگیریم و با حل دستگاه دو معادله و دو مجهول تخمین مناسب را محاسبه کنیم.</p>
    $$ \frac{dLL}{d\mu}=\frac{1}{\sigma^2}\sum_{i=1}^{n}{\left(xi-\mu\right)=0=&gt;\ \ \mu_{ML\ }=\frac{1}{n}\sum_{i=1}^{n}xi} $$<p></p>
    $$ \frac{dLL}{d\sigma}=\sum_{i=1}^{n}{\left(-\frac{1}{\sigma}+\frac{\left(xi-\mu\right)^2}{\sigma^3}\right)=0\Rightarrow n\sigma_{ML\ }^2=\frac{1}{n}\sum_{i=1}^{n}{(xi\ -\ }}\mu_{ML\ })^2 $$
    </div>
    </div>
    </div>
</div>