<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
    <div class="jp-Cell-inputWrapper">
    <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
    </div>
    <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
    </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
    <h3 id="%D9%82%D8%A7%D9%86%D9%88%D9%86-%D8%AA%D8%AC%D8%B1%D8%A8%DB%8C-(Empirical-Rule):">&#1602;&#1575;&#1606;&#1608;&#1606; &#1578;&#1580;&#1585;&#1576;&#1740; (Empirical Rule):</h3><p>طبق این قانون 68% مقادیری که یک توزیع نرمال اختیار می‌کند در فاصله یک سیگما از میو، 95% مقادیر در فاصله دو سیگما از میو و 99.7% مقادیر در فاصله 3 سیگما از میو قرار دارند.</p>
    <h3 id="%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D9%86%D9%85%D8%A7%DB%8C%DB%8C-(Exponential):">&#1578;&#1608;&#1586;&#1740;&#1593; &#1606;&#1605;&#1575;&#1740;&#1740; (Exponential):</h3><p>توزیع نمایی $X\mathtt{\sim}Exp(\lambda)$) با تابع چگالی زیر تعریف می شود:</p>
    $$f_X(x)=\lambda e^{-\lambda x} \quad : \quad x\ge0\;,\: \lambda&gt;0 $$<p>$\lambda&gt;0$ را نرخ توزیع نمایی می نامیم.</p>
    <p>با استفاده از تابع پله داریم:</p>
    $$f_X(x)=\lambda e^{-\lambda x}u(x)$$$$F_X(x)=(1- e^{-\lambda x})u(x)$$<p><strong>خاصیت مهم:</strong> فاصلۀ بین دو نقطۀ تصادفی با توزیع پواسون، دارای توزیع نمایی است.</p>
    <h3 id="%D8%AE%D8%A7%D8%B5%DB%8C%D8%AA-%D8%A8%DB%8C%E2%80%8C%D8%AD%D8%A7%D9%81%D8%B8%DA%AF%DB%8C-%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D9%86%D9%85%D8%A7%DB%8C%DB%8C:">&#1582;&#1575;&#1589;&#1740;&#1578; &#1576;&#1740;&#8204;&#1581;&#1575;&#1601;&#1592;&#1711;&#1740; &#1578;&#1608;&#1586;&#1740;&#1593; &#1606;&#1605;&#1575;&#1740;&#1740;:</h3><p>یکی از خواص جالب توزیع نمایی بدون حافظه بودن آن است، یعنی:</p>
    $$P\{X&gt;t+s|X&gt;t\}=P\{X&gt;s\}$$<p>می‌توان نشان داد که تنها تابع توزیع پیوسته دارای خاصیت بی‌حافظگی، توزیع نمایی است.</p>
    <h3 id="%DA%AF%D8%B4%D8%AA%D8%A7%D9%88%D8%B1-%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D9%86%D9%85%D8%A7%DB%8C%DB%8C:">&#1711;&#1588;&#1578;&#1575;&#1608;&#1585; &#1578;&#1608;&#1586;&#1740;&#1593; &#1606;&#1605;&#1575;&#1740;&#1740;:</h3><p>گشتاور مرتبه $n$-ام توزیع نمایی:</p>
    $$E[X^n]= \int_{0}^{\infty}x^n \lambda e^{-\lambda x} dx$$<p>رابطه بازگشتی برای گشتاور توزیع نمایی:</p>
    $$E[X^n]= \frac{n}{\lambda} E[X^{n-1}]$$<p>بنابراين داريم:</p>
    \begin{align*}
        E[X^0]&amp;=E[1]=1\\
        E[X^1]&amp;=\frac{1}{\lambda}E[X^0]=\frac{1}{\lambda}\\
        E[X^2]&amp;=\frac{1}{\lambda}E[X^1]=\frac{2}{\lambda} \times \frac{1}{\lambda}=\frac{2}{\lambda^2}\\
        &amp;\Rightarrow Var(X)=E[X^2]-(E[X])^2=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}
    \end{align*}
    </div>
    </div>
    </div>
</div>
