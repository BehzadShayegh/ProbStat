<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
    <div class="jp-Cell-inputWrapper">
    <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
    </div>
    <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
    </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
    <h3 id="%D8%AE%D8%B7%DB%8C-%D8%A8%D9%88%D8%AF%D9%86-%D8%A7%D9%85%DB%8C%D8%AF-%D8%B1%DB%8C%D8%A7%D8%B6%DB%8C:">&#1582;&#1591;&#1740; &#1576;&#1608;&#1583;&#1606; &#1575;&#1605;&#1740;&#1583; &#1585;&#1740;&#1575;&#1590;&#1740;:</h3><p>نشان دادیم که $ E[X+Y] = E[X]+E[Y] $ و در حالت کلی:</p>
    $$ E[X_1+X_2+\dots+X_n] = E[X_1]+E[X_2]+\dots+E[X_n] $$<p>به عبارت دیگر امید ریاضی یک عملگر خطی بر روی متغیرهای تصادفی است.</p>
    <p>خاصیت خطی بودن امید ریاضی فارغ از وابسته یا مستقل بودن $X_i$ها برقرار است.</p>
    <p>فرض کنید $  E_1 $، $ E_2 $، ... و $ E_n $ پیشامدهایی متناظر با متغیرهای تصادفی شاخص $ X_i $ باشند. اگر 
    $ E_i $ اتفاق بیافتد، آنگاه $ X_i=1 $ و در غیر این صورت $ X_i=0 $ است. قبلا نشان دادیم که: $E[X_i]=P(E_i)$</p>
    <h3 id="%D8%AD%D8%A7%D8%B5%D9%84%E2%80%8C%D8%B6%D8%B1%D8%A8-%D8%A7%D9%85%DB%8C%D8%AF-%D8%B1%DB%8C%D8%A7%D8%B6%DB%8C:">&#1581;&#1575;&#1589;&#1604;&#8204;&#1590;&#1585;&#1576; &#1575;&#1605;&#1740;&#1583; &#1585;&#1740;&#1575;&#1590;&#1740;:</h3><p><strong>قضیه:</strong> اگر $ X $ و $ Y$ متغیرهای تصادفی مستقل باشند، و $ g(0) $ و $ h(0) $ دو تابع حقیقی باشند، آنگاه:</p>
    $$ E[g(X)h(Y)]=E[g(X)]E[h(Y)] $$<h3 id="%DA%A9%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3-(Covariance):">&#1705;&#1608;&#1575;&#1585;&#1740;&#1575;&#1606;&#1587; (Covariance):</h3><p>کواریانس پارامتری است که میزان وابستگی دو متغیر تصادفی را به یکدیگر نشان می‌دهد. طبق تعریف کواریانس $X$ و $Y$ برابر است با:</p>
    $$ Cov(X,Y)=E[(X-E[X])(Y-E[Y])]  $$<p>به عبارت دیگر برای دو متغیر تصادفی گسسته $X$ و $Y$:</p>
    $$ Cov(X,Y)=\sum_{y} \sum_{x} (x-E[X])(y-E[Y])P_{XY}(x,y) $$<p>و برای دو متغیر تصادفی پیوسته $X$ و $Y$:</p>
    $$Cov(X,Y)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}(x-E[X])(y-E[Y])f_{XY}(x,y)dxdy $$<p>توجه کنید که بر خلاف واریانس که کمیتی همواره نامنفی بود، کواریانس می‌تواند مثبت یا منفی باشد.</p>
    <h3 id="%D9%85%D9%81%D9%87%D9%88%D9%85-%DA%A9%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3:">&#1605;&#1601;&#1607;&#1608;&#1605; &#1705;&#1608;&#1575;&#1585;&#1740;&#1575;&#1606;&#1587;:</h3><p>هرگاه دو متغیر تصادفی $X$ و $Y$، هر دو بالا یا هر دو پایین میانگین خود باشند، کواریانس آن‌ها مثبت است. اگر یکی بالای میانگین خود و دیگری پایین میانگین خود باشد کواریانس آن‌ها منفی است.</p>
    <h3 id="%D8%AE%D9%88%D8%A7%D8%B5-%DA%A9%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3:">&#1582;&#1608;&#1575;&#1589; &#1705;&#1608;&#1575;&#1585;&#1740;&#1575;&#1606;&#1587;:</h3><p>1)
    \begin{align*}
        Cov(X,Y)&amp;=E[(X-E[X])(Y-E[Y])]\\
        &amp;=E[XY-E[X]Y-E[Y]X+E[X]E[Y]]\\
        &amp;=E[XY]-E[X]E[Y]-E[Y]E[X]+E[X]E[Y]\\
        &amp;=E[XY]-E[X]E[Y]
    \end{align*}</p>
    <p>دیدیم که اگر $X$ و $Y$ مستقل باشند داریم: $ E[XY]=E[X]E[Y] $؛ بنابراین:</p>
    $$ Cov(X,Y)=0 $$<p>عکس این قضیه لزوما صحیح نیست. به عبارت دیگر اگر $Cov(X,Y)=0 $، متغیرهای تصادفی $X$ و $Y$ لزوما مستقل نیستند.</p>
    
    </div>
    </div>
    </div>
</div>