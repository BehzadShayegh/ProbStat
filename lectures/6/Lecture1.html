<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3(Variance)">&#1608;&#1575;&#1585;&#1740;&#1575;&#1606;&#1587;(Variance)</h2><p>واریانس بیانگر میزان پراکندگی احتمال حول مقدار متوسط (میانگین) است.</p>
<p>طبق تعریف، توزیع $X$ یا واریانس متغیر تصادفی $X$ به صورت زیر است: 
$$var(X) = E\left((X-E(X))^2\right) = E\left((X-\mu)^2\right) = \sigma^2 $$</p>
<p>واریانس کمیتی نامنفی است. لذا متداول است که آن را با $\sigma_x^2$ یا $\sigma^2$ نشان ‌دهند.</p>
<p>به $E\left((X-\mu)^n\right)$ گشتاور مرکزی مرتبه $n$ام می‌گوییم. در این صورت
$E\left((X-\mu)^2\right)$ گشتاور مرکزی مرتبه دوم است.</p>
<p>واریانس از جنس مربع متغیر تصادفی است.</p>
<h2 id="%D8%A7%D9%86%D8%AD%D8%B1%D8%A7%D9%81-%D9%85%D8%B9%DB%8C%D8%A7%D8%B1">&#1575;&#1606;&#1581;&#1585;&#1575;&#1601; &#1605;&#1593;&#1740;&#1575;&#1585;</h2><p>$\sigma$ را انحراف معیار (StandardDeviation) می‌نامند.</p>
<p>از تعریف امید ریاضی برای متغیر تصادفی گسسته نتیجه می‌شود که:
$$\sigma^2 = \sum_{i} (x_i - \mu)^2 P(x_i)$$</p>
<p>انحراف معیار از جنس خود متغیر تصادفی است.</p>
<h2 id="%D8%AE%D9%88%D8%A7%D8%B5-%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3">&#1582;&#1608;&#1575;&#1589; &#1608;&#1575;&#1585;&#1740;&#1575;&#1606;&#1587;</h2><p><strong>خاصیت اول:</strong> $$\sigma^2 = E[X^2] - (E[X])^2 $$</p>
<p><strong>نتیجه فرعی خاصیت اول:</strong>
$$E(X^2) \ge E^2(X) $$</p>
<p>$E(X^2)$ را میانگین مربعی (meansquare) می‌گویند.</p>
<p><strong>خاصیت دوم:</strong> اگر $Y = aX + b$ باشد، داریم:
$$var(Y) = a^2var(X)$$</p>
<h2 id="%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D8%A8%D8%B1%D9%86%D9%88%D9%84%DB%8C">&#1578;&#1608;&#1586;&#1740;&#1593; &#1576;&#1585;&#1606;&#1608;&#1604;&#1740;</h2><p>اگر خروجی یک آزمایش تصادفی فقط دو حالت موفقیت و شکست را داشته باشد، می‌توانیم این خروجی را با یک متغیر تصادفی شاخص $X$ مدل کرده و آن را یک متغیر تصادفی برنولی نامیم($X\mathtt{\sim}Ber(p)$). اگر موفقيت را 1 و شكست را 0 در نظر بگيريم داريم:
$$P(X=1) = p$$
$$P(X=0) = 1-p$$</p>
<p>امید ریاضی و واریانس این متعیر تصادفی به صورت زیر می‌باشد:
$$E[X] = 1(p) + 0(1-p) = p$$
$$var(X) = E[X^2] - (E[X])^2 =(1^2(p) + 0^2(1-p)) - p^2 = p - p^2 = p(1-p) $$</p>
<h2 id="%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D8%AF%D9%88%D8%AC%D9%85%D9%84%D9%87-%D8%A7%DB%8C">&#1578;&#1608;&#1586;&#1740;&#1593; &#1583;&#1608;&#1580;&#1605;&#1604;&#1607; &#1575;&#1740;</h2><p>اگر یک آزمایش تصادفی با دو خروجی موفقیت (با احتمال$p$) و شکست (با احتمال$1-p$) را $n$ بار تکرار کنیم، و متغیر تصادفی $X$ را تعداد موفقیت ها در $n$ آزمایش در نظر بگیریم، آنگاه $X$ دارای توزیع دوجمله‌ای (binomial) خواهد بود:
$$X\mathtt{\sim}Bin(n,p)$$</p>
$$\text{تابع جرمی احتمال برای متغیر تصادفی دوجمله‌ای}:P_x(k)=P\{X=k\}=\binom{n}{k}p^kq^{n-k} \qquad : \qquad k=0,1,2,\dots,n$$<p>برای سایر مقادیر $k$ داریم: $P(k)=0$</p>
<p>توزیع دوجمله‌ای در حالت خاص $n=1$ تبدیل به توزیع برنولی می‌شود.</p>
<h2 id="%D8%B1%D8%A7%D8%A8%D8%B7%D9%87-%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D8%A8%D8%B1%D9%86%D9%88%D9%84%DB%8C-%D9%88-%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D8%AF%D9%88%D8%AC%D9%85%D9%84%D9%87%E2%80%8C%D8%A7%DB%8C">&#1585;&#1575;&#1576;&#1591;&#1607; &#1578;&#1608;&#1586;&#1740;&#1593; &#1576;&#1585;&#1606;&#1608;&#1604;&#1740; &#1608; &#1578;&#1608;&#1586;&#1740;&#1593; &#1583;&#1608;&#1580;&#1605;&#1604;&#1607;&#8204;&#1575;&#1740;</h2><p>متغیر تصادفی دوجمله‌ای را می‌توانیم به صورت مجموع $n$ متغیر تصادفی مستقل برنولی در نظر بگیریم:
$$X=X_1+X_2+\dots+X_n \quad : \quad X_i\mathtt{\sim}Ber(p),\: X\mathtt{\sim}Bin(n,p)$$</p>
<h2 id="%D9%88%DB%8C%DA%98%DA%AF%DB%8C%E2%80%8C%D9%87%D8%A7%DB%8C-%DB%8C%DA%A9-%D9%85%D8%AA%D8%BA%DB%8C%D8%B1-%D8%AA%D8%B5%D8%A7%D8%AF%D9%81%DB%8C-%D8%A8%D8%A7-%D8%AA%D9%88%D8%B2%DB%8C%D8%B9-%D8%AF%D9%88%D8%AC%D9%85%D9%84%D9%87%E2%80%8C%D8%A7%DB%8C">&#1608;&#1740;&#1688;&#1711;&#1740;&#8204;&#1607;&#1575;&#1740; &#1740;&#1705; &#1605;&#1578;&#1594;&#1740;&#1585; &#1578;&#1589;&#1575;&#1583;&#1601;&#1740; &#1576;&#1575; &#1578;&#1608;&#1586;&#1740;&#1593; &#1583;&#1608;&#1580;&#1605;&#1604;&#1607;&#8204;&#1575;&#1740;</h2><p>1-تعداد آزمایش‌های تصادفی ثابت و برابر $n$ است.</p>
<p>2-آزمایش‌های تصادفی مستقل از هم هستند.</p>
<p>3-هر آزمایش، فقط دو خروجی ممکن شکست و موفقیت دارد.</p>
<p>4-احتمال موفقیت در همه آزمایش‌ها یکسان و برابر $p$ است.</p>

</div>


</div>
